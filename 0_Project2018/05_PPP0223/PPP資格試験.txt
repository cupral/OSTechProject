筆記試験ワークブック

=====暗記箇所=====
ディスプレイ解像度
従来型 1707px * 1019px
新型(18a) 962px * 601px

Pepperの基準の声
vct=135 rspd=110

ユーザが立ち去ったと判断すべき秒数
Pepperの質問に20秒(推奨)応答がなかった時

QiChatを使用する際は
e:Dialog/Understoodを使用すること

撮影した画像や動画は 
/home/nao/recordings/cameras/ の配下に保存されます。 

写真撮影で生成される画像ファイルは
全てjpg形式

RecordSoundボックス
保存形式はwavかoggです。

RecordSoundボックスは
GetFileName / Wait/Rec.SoundFileから構成されています。

=====コマンド=====

sshコマンドでリモート接続後、ログを確認するqicliコマンド
qicli log-view
Linuxコマンドで直接ログファイルを参照

tail -f /var/log/naoqi/tail-naoqi.log
Pepper本体にインストールされている任意のアプリを起動するには、以下のコマンドを実行します。

qicli call ALAutonomousLife.switchFocus "sampleapp/."
sshからのqicliコマンドでも腕のセーフティの解除
qicli call ALMotion.setExternalCollisionProtectionEnable "Arm" 0
ssh コマンドでリモート接続後に
NAOqi OSだけを再起動させるコマンド

nao restart
ssh コマンドでリモート接続語、ログを確認するqicliコマンド

qicli log-view
Linuxのコマンドで直接ログファイルを参照するコマンド

tail -f /var/log/naoqi/tail-naoqi.log

=====重要項目=====

【Robot IDの記載箇所】
DataMatrixコードと共に緊急停止ボタン付近のシールに印字されています。

【製品型番/請求書表記】
Robot ID(BpdyID)AP990483以降は
製品型番TR18AA1(請求書表記 18a)となります。

【箱からの取り出し方での注意点】
・梱包箱を立てた状態で蓋を開ける
　※上部ミミ(フラップ)を固定用の穴に差し込み、固定すること。
・充電フラップを閉じる
　(閉じない状態で梱包すると閉じる際に緩衝材が浮き、
　　故障の元になりますので必ず閉じてください。)
・蓋を開ける
　※上部ミミ(フラップ)を固定用の穴に差し込み、固定すること

【Pepperを移動させる際の注意事項】
充電フラップをあげる。※本機のオムニホイールを作動させない為

【Pepperを持ち上げての移動】
電源をきり、緊急停止ボタンを押す、セーフレスト状態にし、
背後から本機を支えながら腰とひざのピンを取り付ける
胸の下に手を入れて持ち上げる

【Choregrapheのインストール時の注意】
MicroSoft Window7 および8,1 (Windows10は正式対応していません。)

【起動トリガー条件例】
例：12時以降の30分に起動する
'Launchpad/Hour'>= 12 && 'Launchpad/Minute'==30&&('Launchpad/FocusedActivity'!="sampleapp/.")~60

'Launchpad/Hour'>= 12
12時以降
 &&
論理演算子AND
 'Launchpad/Minute'==30
各30分
&&
論理演算子AND
('Launchpad/FocusedActivity'!="sampleapp/.")~60
・指定したアプリケーションが60秒以上起動していない
・指定の秒数移譲演算子の前の条件式が真

※バーチャルロボットには対応していません。
前と以外の起動トリガー条件に指定できる情報は、APIのLaunch trigger conditionsの項目にまとめられています

【メモリウォッチャーのデフォルト取得間隔】
メモリの取得間隔がデフォルトで１秒に設定されています。


【ログビューア】
内部のログを確認できます。ログレベルを操作することで、
Fatal、Error、Warning、info、Verbose、Debugの６種類から絞込できます。

設定画面からログレベルの設定が可能です。
Fatal : 致命的なエラー
Error : エラー
Warning : 警告
Info : 情報
Debug : デバッグ

【AnimatedSay設定】
disabled(無効) random(ランダム) contextual(文脈から判断)
の3種類からのうちいずれかを選択します。

QiChat構文
構文
解説
concept
concept構文を使うと反応させたい複数の単語をひとまとめにして管理できます。
1行目で準備をし、3行目で使用しています。
使用する場合は登録した単語[yes]の前に「~」をつけます。
uX:(反応する単語)発話内容

Xは1~7の数字
左記の構文とインデントを組み合わせると反応する単語に順序を付与できます。
上記サンプルの例では、「はい」という返答の後でなければ
「犬」または「猫」という単語に反応しません。
$onStopped= データ
Dialogボックスの戻り値として発生させるデータを指定できます。

ｱﾆﾒｰｼｮﾝ	
^start(ｱﾆﾒｰｼｮﾝ名)
^wait(ｱﾆﾒｰｼｮﾝ名)
開始と終了を明示的に指定することで
中断させない

^run(ｱﾆﾒｰｼｮﾝ名)
中断されることがある
サウンド
^startSound(ｻｳﾝﾄﾞﾌｧｲﾙ名)
^waitSound(ｻｳﾝﾄﾞﾌｧｲﾙ名)
開始と終了を明示的に指定することで
中断させない

^runSound(ｻｳﾝﾄﾞﾌｧｲﾙ名)
中断されることがある

vct
50~200(デフォルト:100)
声の高さ
rspd
50~400(デフォルト:100)
声の速さ
pau
ミリ秒
一時停止
vol
0~100%
音量

【モーション作成】
モーション作成時はPepperの点灯や故障リスクを軽減するため可能な限りバーチャルロボットで動作を確認してからPepper本体で動作確認をします。

【タイムラインエディター】
モーションとモーションの間を滑らかにしたい場合は、
Timelineボックスの編集(鉛筆ボタンから)
タイムラインエディターを表示させ、2点間の動作の調整を行えます。

【プラナームーブ】
平面動作の作成機能を使用することで、自由な起動を定義することもできます。
「プロジェクトの内容」パネルの「＋」ボタンをクリックし、「新規プラナームーブ」をクリックして名前を入力すると、プラナームーブエディタが開きます。

作成したプラナームーブは.pmt形式のファイルとして保存されるので、フローダイアグラムにドラッグすることで使用できます。

【モーション開発時の注意】
開発時(Choregraphe)はレストモードにしておきます。通常の直立状態でも負荷がかかっています。

【画像の撮影と再生】
TakePictureBOXで Top/Bottomを指定できる。
自動的に拡張子が付与されますので、設定画面で指定するファイル名には拡張子を含めないように

【画像の表示時の工夫】
ファイル名の後に？を付け、その後ろに乱数や現在時刻をつけたものをURIにします。またNAOqi2.3からはshowImageNoCacheというメソッドが用意されているので、これを使用するとキャッシュに残りません。


【動画の撮影】
ビデオデバイス用のAPIであるALVideoDeviceのrecordVideoメソッドを用いて動画の録画もできましたが、APIの1.2以降ではALVideoRecorderのstartRecordingメソッドが推奨されています。

【動画の再生】
ボックスの結線でも簡易的に動画の操作は可能ですが、スクリプトでの操作も可能です。その場合はALTabletServiceのメソッドを使います。
メソッド名
概要
getVideoLength
動画の再生時間を取得します。
getVideoPosition
動画の再生位置を取得します
pauseVideo
動画の停止します
playVideo
動画を再生します
resumeVideo
動画の再生を再開します
stopVideo
動画の再生を停止します

【音の再生】
設定は音量や再生開始位置、バランス、ループなどを設定できます。
PlaySoundボックスはGetAttachedFileボックスとPlaySoundFileボックスから構成されています。

【タッチ操作時の座標取得】
On touch move　：ディスプレイ上でスライド
On touch down　：ディスプレイに指がくっついた
On touch up　　  ：ディズプレイから指が離れた

onTouchedからは操作されたディスプレイ上の座標が出力されます。

また連毒タッチや同時タッチと言ったイレギュラーな操作に対応するには
OnlyOnceボックスを使用するといいでしょう。

【QiMessaging JavaScript】
ディスプレイとPepperのやりとりはQiMessagingというJavaScriptのライブラリを使用する必要があります。


【ライフサイクル】
Disabled
電源投入直後の状態。電源は入っているが
A-Lifeが動作していない状態
Solitary
A-Lifeが起動し、Interactiveアクティビティを
起動するトリガーの受付を待っている状態。
ユーザを惹きつけるようなアプリや
定期動作アプリなどを実行して待ちます。
ユーザを認識したらInteractiveへ遷移します。
Interactive
ユーザとやり取りをしている状態。
Interactiveへ遷移するのはSolitaryからのみです。
Safeguard
緊急時の状態。Pepper自信が復旧を試みます。
復旧できればSolitaryへ遷移し、
復旧できなければDisabledへ遷移します。


Engagement Mode
Pepper がユーザーを認識した後、
多くはそのユーザーとのInteractive アクティビティ中に、
外部刺激にどの程度反応するか設定します。
Unengaged
外部刺激に反応します。
FullyEngaged
外部刺激に反応しません。
SemiEngaged
外部刺激に反応しますが、すぐにユーザーのほうに向き直します。
Tracking Mode
Pepper がどの程度体を動かしてユーザーを追跡するか設定します。
Head
頭を動かして追跡します。
BodyRotation
体を傾けて追跡します。
WholeBody
全身を使って追跡しますが、旋回はしません。
Sound Stimulus
音に反応するかどうかを設定します。
Movement Stimulus
動きに反応するかどうかを設定します。
People Stimulus
人物識別をして反応するかどうかを設定します。
Touch Stimulus
タッチセンサーによる刺激に反応するかどうかを設定します。
【BreathingのON/OFF設定方法】
Breathingについては制御をするボックスはありませんので、
ALAutonomousMovesのメソッドを使用して制御する必要があります。
メソッド名
備考
getVideoLength
動画の再生時間を得るためのメソッドです。
getVideoPosition
動画の再生位置を得るためのメソッドです。
再生していない場合は-1です。
playVideo
動画を再生させるメソッドです。
動画再生中の戻り値は true です。
pauseVideo
動画を一時停止させるメソッドです。
動画を再生中の戻り値は true です。
resumeVideo
動画の再生を再開させるメソッドです。
動画を再生中の戻り値は trueです。
stopVideo
動画を停止させるメソッドです。
プレイヤが開いている場合の戻り値は true となります。

【ステータスLEDの役割】
色(光り方)
状態
白(点灯)
正常
緑(点滅)
通知情報あり
黄(早く 2 回点滅)
警告
赤(早く 2 回点滅)
エラー
赤(遅く点滅)
使用不可
ステータスLEDの点滅
緑：Pepperは、進行中のアクションについてInfo通知によってフィードバックを返します。
黄：警告通知は、問題にあなたの注意や行動が必要な場合に発生します。
　　　Pepperは引き続き使用できますが、一部の機能が利用できない劣化モードで動作するか、
　　　問題を解決しないとすぐに使用できなくなる可能性があります。
赤：通知は、Pepperの 1つまたはすべての機能 が使用できなくなった場合に発生します。
　　ヒントを使用して問題を解決してください。
　　問題が解決しない場合は、カスタマーサポートに連絡し、
　　エラーIDを提供してください。

【耳のLEDの制御、数】
耳のLEDは10個で個々に点滅を設定できる


【視覚系VisionAPI】
Pepperはカメラを使って、
写真撮影、QRコード読取り、環境の明るさ検知、RedBall検知などができます。
ALBarcodeReader、ALPhotoCaptureなど
getCameraID
設定済みのカメラを取得する
setCameraID
使うカメラをセットする
getPictureFormat
設定済みの写真フォーマットを取得する
setPictureFormat
写真のフォーマットを設定する
getResolution
設定済み解像度を取得する
setResolution
写真の解像度を設定する
takePicture
写真を撮って、指定のパスに保存する
感情認識
getMaximumdetectionRange
最大検知距離を取得
setMaximumDetectionRange
最大検知居距離を設定
resetPopulation
検知した人をリセットする
setFastModeEnabled
FaseModeをセットする
ALPeoplePerceptionのALMemory Key List
PeoplePerception/Person/<ID>/Distance
人の距離
PeoplePerception/Person/<ID>/PresentSince
認識から経過した時間
PeoplePerception/Person/<ID>/RealHeight
人の身長
PeoplePerception/Person/<ID>/ShirtColor
人のシャツの色

【GetExpressionボックス】
GetExpressionボックスを使用すると
ユーザの表情から感情を読み取ることができます。
読取りが可能な環状は平常、怒り、喜び、驚き、悲しみ

Pepperは頭頂部のマイクを使って話しかけられた音を認識し、スピーカーから音声を再生できます。これら音声に関する機能はAudioAPIとして提供されています。
(この機能はNAOqi2.5.5では使えません。添付のサンプルアプリをご覧になる場合はご留意ください。)


【ALVoiceEmotionAnalysisProxyの主なメソッド】
setParameter
認識するときの音声の長さを設定
subscribe
音声の感情情報を取得するEmotionRecognizedイベントを発生させる
unsubscribe
EmotionRecognizedイベントを停止する

ページ
項目
主な内容
HOME
NAOqi
バージョンやバッテリーの残量
Head&Body ID
現在の設定言語

NetWork
IPアドレス

Build
Build Date
Build ID
Setting
Security
セーフティ機能のOFF
Hardware

Deviceの接続形式や関節部分の温度
Memory

内部メモリの状態
Tethering

Wi-Fiによるテザリングの設定
10.3.インタラクション分析
PepperforBizではアプリの実行統計を得ることが出来ます。
得られる統計情報は以下の通りです。
・タスク起動回数
・インタラクション人数
・年齢層
・性別
・感情
インタラクション分析は、(https://interaction-analytics.aldebaran.com/)にて確認いただけます。
感情の取得
ALVoiceEmotionはNAOqi 2.5.5では使えません

【インタラクション分析への反映方法】
Event label>:=
<ApplicationID>"/"(<BehaviorName>"/")? <LabelName>"/"<LabelParam>
(<BehaviorName> "/")?は?となっているため、省略して構いません。
<LabelName>には任意の文字列を設定します。
<LabelParam>には選択し等を設定します。

4.Send to cloudにチェックを入れる
設定された情報 、『インタラクション分析』



【名称(Pepper)に関する制限】
開発したソリューション・製品の名前に小喬の名前に商標Pepperを連動くして使用することを禁止致します、ただし、Pepperとの間に for ~　やPepper用~の文言を挿入することは制限しません。
☓　▲▲販売促進Pepper (Pepperと商品名が連毒して使用されている為☓)
◯　▲▲販売促進 for Pepper (for がPepeprとの間にあるため◯)
◯　Pepper用▲▲販売促進アプリ (用がPepperとの間にあるため◯)

Pepper画像について
広告、告知物に、無断でソフトバンクロボティクス者およびソフトバンクグループ会社のホームページ等から写真画像、Pepeprロゴ、イラストなどのコンテンツを使用することは禁止されています。PepperforBizをご使用で公式画像が必要な場合は営業担当もしくはPepeprforBizお問い合わせ窓口へ連絡する必要があります。


ビヘイビアパス
ビヘイビアパスは以下の書式(BNF)になります。
<ビヘイビアパス>:= <ApplicationID>  "/" <Path>
感情の取得
ALVoiceEmotionはNAOqi 2.5.5では使えません
<Event label>:=
<ApplicationID>"/"(<BehaviorName>"/")? <LabelName>"/"<LabelParam>
(<BehaviorName> "/")?は?となっているため、省略して構いません。
<LabelName>には任意の文字列を設定します。
<LabelParam>には選択し等を設定します。

【新機能SLAM機能β】
SLAMとは自己位置推定と環境地図作成を同時に行う機能です。
PepperのSLAMはALNavigationAPIに収められています。
ALNavigationAPIについて柿URLからALNavigationを御覧ください。
(http://doc.aldebaran.com/2-5/naoqi/motion/exploration-api.html)

【新機能　中国語(繁体)の対応】
中国語(繁体)に対応しました。
対応範囲はChoragraphe(Tools/Content and Samples),NAOqi API(ASP Engine>TTS Engine)となります。
詳しくは柿URKから「MandarinTaiwanese」を御覧ください。
(http://doc.aldebaran.com/2-5/family/pepper_technical/languages_pep.html-language-codes-pep)

【翻訳】
従来のSay/AniamtedSayボックでは発話するテキストを変湯数する他にボックスごとに発話する言語を設定する必要がありましたが、Choragraphe2.5では言語設定をプロジェクトの設定から行うようになりました。仕組みとしてはぷrジェクトの中に"translations"フォルダが作成され、翻訳情報が記録されます。この翻訳情報に基づいて翻訳されます。


1.プロジェクトファイルのプロパティをクリック
2.プロジェクトのプロパティ画面の右側、ロボアプリの対応言語で翻訳したい言語にチェックを入れます。
3.OKボタンをクリック
4.Say/AnimatedSayボックスをフローダイアグラムにドラッグ＆ドロップ
5.Choragpraphe左上のファイルからアプリをローカライズするをクリック
6.翻訳エディタQtLinguistが起動する
7.QtLinguistの左側コンテキストから翻訳したいボックスを選ぶ
このコン的ウトに表示される内容はビヘイビアフォルダ名/behavior.xar/ボックス名
で表現されます。
8.文字列から編集したい文字列を選び、それぞれの言語のテキストを編集する。
9.ファイルから全てを保存をクリックする
10.Qt Linguistを終了する。
これで  Pepper  発話する言語に合わせ設定したテキストが発話されます。

*注意1 多言語で発話設定する場合、英語訳が最上位にあるためボックス テキストパラメータが英語となります。こ 時ボックス テキストパラメータに日本語で入力すると、English 訳 部分に日本語を入力したことになり、翻訳が機能しない場合があります。これを回避するに Qt Linguist で English 訳と日本語訳を書き換えるか、プロジェクト プロパティで  apanese だけにチェックを入れ   をクリックして English 訳ファイルを削除し日本語を最上位にします。そ 後プロジェクト プロパティで English にチェックを入れると English 訳ファイルが日本語 下位に作成され、そ 後配置するボックス 全てテキストパラメータが日本語訳になり、日本語訳 位置に日本語テキストが収まります。

【従来のボックスとの置き換え】
Choragprahe2.5.5では過去のChoregrapheバージョンで作られたSayやAniamtedSayなどを編集、保存することが出来ます。しかしChoregraphe2.5.5で作られたSayやAnimatedを以前のバージョンのChoregraphede編集することも実行することも出来ませんので注意してください


アプリ開発　入門編        
【バーチャルロボットがPepperでない場合】
ロボットモデルをPepperY20(V16)にする

【WindowsPCでGPUとの相性問題が発生した場合】
コマンドプロンプトで
> choregraphe-bin.exe —no-ogre

【Pepperのvct,rspd推奨値】
135,110

【QiChat】
^stayInScope u*の範囲に留まってくださいを指示
u:(e:Dialog/NotSpeaking15) タイムアウト用 目安は15~20
※5/1015/20しか設定できない

【ポーズライブラリ】
StandZero/StandInit/Stand

【セリフにモーションを組み込む】
^mode(モード名) 動作モードを切り替える(disabled/random/contextual)
^start(モーション名)
^wait(モーション名)

【タイムラインは500フレーム以内まで】
保守性を考慮して１つのTimelineボックスは500フレームまで

【対人イベント】
EngagementZones / PeoplePerceptionで始まる
ゾーン1,2,3はそれぞれ1.0m以内/1.2m以内/1.2m以上に設定

【画像表示】
画像のフォーマット jpg/png
参照パス img/****.jpg

【ディスプレイ解像度】
962px * 601px

【TabletTouchの仮想解像度】
1280px *800px

【QiMessaging JavaScript読込】
<script src="/libs/qimessaging/2/qimessaging.js"></script>

【htmlのクリック認識】
onClickではなくtouchstartやtouchendを使用すべきです。

【ディスプレイの表示を消す】
HideWebViewを使用する

【ディスプレイ表示の注意点】
・字はできるだけ大きくする
・UI要素の配置が上下左右に偏らないようにする
・文字と背景のコントラスト比はできるだけ高くする
・ボタン連打に対応する
・タッチした時に表示が上下左右にブレないようにする
・ピンチイン/ピンチアウトで拡大/縮小しないようにする
・アプリ起動中はバブル状態に戻らないようにする
・アプリが終了したら表示した内容を消す
・操作は音声とディスプレイ両方でできるようにする

【オートノマスライフ】
Basic AwarenessとBreathing Animationの自動実行

【アプリアイコン】
プロジェクトトップにicon.pngというファイルを配置します。

【ライフサイクル】
Solitary/Interactive/Safeguard/Disabled

【イベント発生】
> qicli call ALMemory.raiseEvent "<EventName>" <param>
> qicli call ALMemory.raiseEvent "Launchpad/NumPeopleZone1" 2











